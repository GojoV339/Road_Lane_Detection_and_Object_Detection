{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d55b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: /home/toji339/Documents/Sem-5/Computer Vision/Road-Lane-Detection-and-Object-Detection\n",
      "Python Path Contains project roor: False\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "print(\"Working dir:\", os.getcwd())\n",
    "print(\"Python Path Contains project roor:\", os.getcwd() in sys.path)\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.insert(0, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bdaff1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'losses' from '/home/toji339/Documents/Sem-5/Computer Vision/Road-Lane-Detection-and-Object-Detection/losses.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. imports and device\n",
    "import importlib\n",
    "import time\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# import your modules\n",
    "import drive_dataloader, drive_object_detection_model, utils, train, test, losses\n",
    "\n",
    "importlib.reload(drive_dataloader)\n",
    "importlib.reload(drive_object_detection_model)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(train)\n",
    "importlib.reload(test)\n",
    "importlib.reload(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e97a8a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 8333\n",
      "Batch images: torch.Size([4, 3, 640, 640]) num targets: 4\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = drive_dataloader.make_loaders(\n",
    "    root=os.path.join(os.getcwd(), \"Datasets\", \"Drive_India\"),\n",
    "    batch_size=4, input_size=640, num_workers=2\n",
    ")\n",
    "print(\"Train samples:\", len(train_loader.dataset))\n",
    "images, targets = next(iter(train_loader))\n",
    "print(\"Batch images:\", images.shape, \"num targets:\", len(targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ebfade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace(data_root='./Datasets/Drive_India', batch_size=8, input_size=512, num_workers=0, num_classes=24, epochs=1, lr=0.01, step_step=8, gamma=0.1, log_dir='./runs', ckpt_dir='./checkpoints', test_after_epoch=False, seed=42)\n"
     ]
    }
   ],
   "source": [
    "# 2. hyperparams & paths (edit these)\n",
    "cfg = SimpleNamespace()\n",
    "\n",
    "cfg.data_root = \"./Datasets/Drive_India\"     # path to dataset\n",
    "cfg.batch_size = 8\n",
    "cfg.input_size = 512\n",
    "cfg.num_workers = 0\n",
    "cfg.num_classes = 24\n",
    "cfg.epochs = 1\n",
    "cfg.lr = 0.01\n",
    "cfg.step_step = 8\n",
    "cfg.gamma = 0.1\n",
    "cfg.log_dir = \"./runs\"\n",
    "cfg.ckpt_dir = \"./checkpoints\"\n",
    "cfg.test_after_epoch = False   # set True to evaluate test each epoch (slower)\n",
    "cfg.seed = 42\n",
    "\n",
    "# reproducibility (not perfect but helps)\n",
    "import random, numpy as np\n",
    "random.seed(cfg.seed); np.random.seed(cfg.seed); torch.manual_seed(cfg.seed)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(cfg.seed)\n",
    "\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e8ffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created. #params: 6.14 M\n",
      "Anchors: torch.Size([64512, 4])\n"
     ]
    }
   ],
   "source": [
    "# 4. create model, anchors, optimizer\n",
    "net = drive_object_detection_model.DriveSingleShotModel(num_classes=cfg.num_classes, input_size=cfg.input_size).to(device)\n",
    "anchors = utils.build_anchors_for_model(net, input_size=cfg.input_size)   # normalized anchors tensor\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=cfg.lr, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=cfg.step_step, gamma=cfg.gamma)\n",
    "\n",
    "print(\"Model created. #params: %.2f M\" % (sum(p.numel() for p in net.parameters())/1e6))\n",
    "print(\"Anchors:\", anchors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc512fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before step: 390941.84375 {'cls': 390366.15625, 'box': 287.8451843261719, 'pos': 151}\n",
      "Step done — loss after update (recompute):\n",
      "Loss after step: 3923.146484375 {'cls': 3397.6669921875, 'box': 262.73968505859375, 'pos': 151}\n"
     ]
    }
   ],
   "source": [
    "# one_image_train.py (notebook cell)\n",
    "import os, torch\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from drive_dataloader import DriveIndiaDataset, collate_fn, move_batch_to_device\n",
    "from drive_object_detection_model import DriveSingleShotModel\n",
    "from utils import build_anchors_for_model\n",
    "from losses import compute_losses\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ROOT = os.path.join(os.getcwd(), \"Datasets\", \"Drive_India\")\n",
    "\n",
    "# 1) build dataset and pick one index (e.g., first image of train1)\n",
    "dataset = DriveIndiaDataset(ROOT, split=\"train1\", input_size=640, augment=False)\n",
    "single_idx = 0   # change if you want another image\n",
    "single_ds = Subset(dataset, [single_idx])\n",
    "\n",
    "loader = DataLoader(single_ds, batch_size=1, shuffle=False, num_workers=0,\n",
    "                    pin_memory=False, collate_fn=collate_fn)\n",
    "\n",
    "# 2) model, anchors, optimizer\n",
    "model = DriveSingleShotModel(num_classes=24, input_size=640).to(device)\n",
    "anchors = build_anchors_for_model(model, input_size=640)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "# 3) single training step (one epoch with one batch)\n",
    "model.train()\n",
    "for images, targets in loader:\n",
    "    images, targets = move_batch_to_device((images, targets), device)\n",
    "    outputs = model(images)\n",
    "    loss, parts = compute_losses(outputs, anchors, targets, model.input_size, num_classes=24)\n",
    "    print(\"Loss before step:\", loss.item(), parts)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"Step done — loss after update (recompute):\")\n",
    "    with torch.no_grad():\n",
    "        outputs2 = model(images)\n",
    "        loss2, parts2 = compute_losses(outputs2, anchors, targets, model.input_size, num_classes=24)\n",
    "    print(\"Loss after step:\", loss2.item(), parts2)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456068eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Forward+backward time: 0.432s | loss: 88903.359 | parts: {'cls': 88757.5625, 'box': 72.89772033691406, 'pos': 39}\n",
      "Fast decode time: 0.011s | detections in batch[0]: 200\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFast decode time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt1-t0\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms | detections in batch[0]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(fast_preds[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m det \u001b[38;5;129;01min\u001b[39;00m fast_preds[\u001b[32m0\u001b[39m][:\u001b[32m10\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mbox\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mdet\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m, det[\u001b[32m1\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m, det[\u001b[32m2\u001b[39m])\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# 5) quick sanity: visualize if needed (optional)\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# Evaluate current `net` on a small subset and on full val/test if desired\n",
    "import time\n",
    "from utils import decode_outputs, compute_map50, move_batch_to_device\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "net.eval()\n",
    "\n",
    "def evaluate_loader(loader, max_batches=None, conf_thresh=0.05):\n",
    "    preds=[]; gts=[]\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (images, targets) in enumerate(tqdm(loader, desc=\"Eval loader\")):\n",
    "            if max_batches is not None and i >= max_batches: break\n",
    "            images, targets = move_batch_to_device((images, targets), device)\n",
    "            outputs = net(images)\n",
    "            batch_preds = decode_outputs(outputs, anchors, input_size=net.input_size, conf_thresh=conf_thresh, iou_thres=0.5)\n",
    "            preds.extend(batch_preds); gts.extend(targets)\n",
    "    mAP50, per_class_ap = compute_map50(preds, gts, num_classes=cfg.num_classes)\n",
    "    return mAP50, per_class_ap, time.time() - t0\n",
    "\n",
    "# Quick smoke: evaluate on 10 val batches (fast)\n",
    "quick_map, per_class, sec = evaluate_loader(val_loader, max_batches=10)\n",
    "print(f\"Quick val (10 batches) mAP50: {quick_map:.4f}  time: {sec:.1f}s\")\n",
    "\n",
    "# Full val (uncomment when ready; may be slow)\n",
    "#full_val_map, _, sec_full = evaluate_loader(val_loader, max_batches=None)\n",
    "#print(f\"Full val mAP50: {full_val_map:.4f}  time: {sec_full:.1f}s\")\n",
    "\n",
    "# Quick test (10 batches)\n",
    "quick_test_map, _, sec_test = evaluate_loader(test_loader, max_batches=10)\n",
    "print(f\"Quick test (10 batches) mAP50: {quick_test_map:.4f}  time: {sec_test:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8002bc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Road-Lane-Detection-and-Object-Detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
